
---
title: "Meta-Analysis"
output: html_document
---

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(metafor)
library(meta)
source("R/forester_custom.R")
```

```{r}
rdas <- list.files(
  path = "results",
  pattern = ".rda",
  full.names = TRUE
)
for (rda in rdas) {
  load(rda)
}
rm(rdas, rda)
# create a list of all rda files with "result" suffix
# check for sites we may want to exclude
googlesheets4::gs4_deauth()
site_google_url <- "https://docs.google.com/spreadsheets/d/1epcYNd_0jCUMktOHf8mz5v651zy1JALD6PgzobrGWDY/edit?usp=sharing"
site_params <- googlesheets4::read_sheet(site_google_url, sheet = 1)
site_avails <- googlesheets4::read_sheet(site_google_url, sheet = 2)
sorted_sites <- site_avails %>%
  filter(date_v3_received == 1) %>%
  pull(siteid) %>%
  paste("results", sep = "_")

# sorted_sites <- c("NWU_results","UPITT_results", "MGB_results", "UPENN_results", 
#                   "VA1_results", "VA2_results", "VA3_results", "VA4_results", "VA5_results") #"UPENN_results", "UPITT_results", "MGB_results", "FRBDX_results")
```


```{r}
site_results <- mget(ls(pattern = "results"))
```


```{r echo=TRUE}
sorted_sites <- sorted_sites[!(sorted_sites %in% c("BCH_results"))]
site_results[['BCH_results']] <- NULL
```

change ```neuro_chr_to_analyze``` in order to change analysis to 'neuro_postCentral', 'neuro_postPeripheral', 'neuro_postBoth'
change ```neuro_type_analyze``` in order to change analysis to 'cpns_results' or 'binary_results'

```{r}
neuro_chr_to_analyze <- "neuro_postCentral"
neuro_type_analyze <- "binary_results"
neuro_type_analyze <- "cpns_results"

if (neuro_type_analyze == "binary_results") {
  neuro_chr_to_analyze <- ""
} else {
  neuro_type_analyze <- "cpns_results"
}

site_results <- mget(ls(pattern = "result"))
site_results <- site_results[sorted_sites]

get_life_row <- function(df,
                         outcome = "time_severe_reg_elix",
                         period = "first_hosp_results",
                         neuro_type = neuro_type_analyze) {
  life_output <- df[[c(period, neuro_type, outcome, "average_survival", "survf")]]
  bind_cols(life_output[c("surv", "std.err", "time", "strata")]) %>%
    mutate(
      site = df$site,
      #n_site = df[[c(period, neuro_type, outcome, "cox")]]
    )
}
#df = site_results[[1]]
get_cox_row <- function(df,
                        outcome = "time_severe_reg_elix",
                        period = "first_hosp_results",
                        neuro_type = neuro_type_analyze) {
  cox_output <- df[[c(period, neuro_type, outcome, "cox")]]
  coefficients(cox_output) %>%
    data.frame() %>%
    mutate(
      site = df$site
      #n_site = cox_output$n
    ) %>%
    rownames_to_column("variable")
}
```


```{r}
outcomes <-
  c(
    "time_first_discharge_reg_elix",
    "time_severe_reg_elix",
    "time_deceased_reg_elix"
  )

meta_results <- list()

for (outcome_i in outcomes) {
  meta_results[[outcome_i]] <-
    site_results %>%
    lapply(get_life_row, outcome = outcome_i) %>%
    bind_rows() %>%
    mutate(outcome = outcome_i)
}

res_dat <- bind_rows(meta_results)
res_dat_surv <- res_dat[[1]] %>% data.frame()
colnames(res_dat_surv) <- c("None", "PNS", "CNS")

res_dat_std.err <- res_dat[[2]] %>% data.frame()
colnames(res_dat_std.err) <- c("None", "PNS", "CNS")
res_dat_std.err <- res_dat_std.err  %>%
  cbind(., res_dat[3:5]) %>% 
  pivot_longer(cols = None:CNS,  names_to = "strata", values_to = "std.err")

res_dat_surv <- res_dat_surv %>%
  cbind(., res_dat[3:5]) %>% 
  pivot_longer(cols = None:CNS,  names_to = "strata", values_to = "surv") %>% 
  left_join(., res_dat_std.err) %>% 
  mutate(std.err = ifelse(is.nan(std.err), NA, std.err)) %>%
  filter(!time < 0) %>% 
  add_count(site, strata, outcome, name = "n_timepoints") %>%
  complete(time, site, nesting(strata, outcome)) %>%
  mutate(surv = if_else(is.na(surv) & time == 0, 1, surv)) %>%
  group_by(site, strata, outcome) %>%
  arrange(time) %>% 
  fill(surv, .direction = "down") %>%
  fill(std.err, n_timepoints, .direction = "down") %>%
  #fill(std.err, n_site, n_timepoints, .direction = "downup") %>%
  #filter(n_timepoints >= 5, time >= 0) %>%
  ungroup()

# add total number of events for each site
calc_events <- function(site_results, outcome) {
  
  events <- site_results[["first_hosp_results"]][["cpns_results"]][[paste(outcome)]][["event_table_obfs"]] %>% 
  add_count(status, name = "n_timepoints") %>% 
  complete(time, nesting(status)) %>%
  arrange(time) %>% 
  group_by(status) %>%
  select(-n.risk, -n.censor) %>% 
  fill(n_timepoints, .direction = "downup") %>%
  fill(n.event, .direction = "downup") %>% 
  #filter(time %in% c(1, 30, 60)) %>% 
  ungroup()
  
  return(events)
  
}

# use for loop to calculate these numbers across sites

events_list <- list()

for(i in 1:length(site_results)) {
  
  severe_results <- calc_events(site_results[[i]], "time_severe_reg_elix") %>% 
    mutate(site = site_results[[i]][['site']],
           outcome = "time_severe_reg_elix")
  
    death_results <- calc_events(site_results[[i]], "time_deceased_reg_elix") %>% 
    mutate(site = site_results[[i]][['site']],
           outcome = "time_deceased_reg_elix")
    
    discharge_results <- calc_events(site_results[[i]], "time_first_discharge_reg_elix") %>% 
    mutate(site = site_results[[i]][['site']],
           outcome = "time_first_discharge_reg_elix")
    
    event_results <- rbind(severe_results, 
                           death_results, 
                           discharge_results)
  
  events_list[[i]] <- event_results
  
}


events_table <- do.call(rbind.data.frame, events_list) %>% 
  rename(strata = "status") 

events_table$strata <- recode(events_table$strata,
                              `neuro_post=None` = "None",
                              `neuro_post=Peripheral` = "PNS", 
                              `neuro_post=Central` = "CNS")

res_dat_surv <- left_join(res_dat_surv, 
                           events_table %>% select(site, outcome, strata, time, n.event), 
                           by = c("site", "outcome", "strata", "time"))

res_dat_surv <- res_dat_surv %>% 
  group_by(site, strata, outcome) %>% 
  fill(n.event, .direction = "downup") %>% 
  mutate(n.event = replace_na(n.event, 0))
  

# sum total number of events from each site
# Chaun Q: should this be calculated per strata?
calc_total_counts <- res_dat_surv %>% 
  data.frame() %>% 
  group_by(site, outcome, strata) %>% 
  summarize(total_event = sum(n.event)) %>% 
  mutate(total_event = replace_na(total_event, 0)) %>% 
  ungroup()

res_dat_surv <- res_dat_surv %>% 
  left_join(., calc_total_counts, by = c("site", "outcome", "strata"))

```
 
```{r}
save(res_dat_surv, file = "res_dat_surv.rda")
```


```{r}
get_surv <- function(surv, std.err, site) {
  if (length(surv) == 1) {
    return(surv)
  } else {
    junk <- rma(y = surv, sei = std.err, random = ~ 1 | site, method = "DL") # metafor for each strata
    return(c(junk$beta))
  }
}
get_se <- function(surv, std.err, site) {
  if (length(std.err) == 1) {
    return(std.err)
  } else {
    junk <- metafor::rma(y = surv, sei = std.err, random = ~ 1 | site, method = "DL") # metafor for each strata
    return(c(junk$se))
  }
}
# res_dat %>%
#   filter(is.nan(std.err))
```

## Meta-analysis with Adjusted Curves

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# test <- res_dat_surv %>% 
#   filter(#site == "NWU" | site == "UPENN", 
#          strata == "PNS", 
#          outcome == "time_deceased_reg_elix")
# plot(test$time, test$surv)
# 
# junk <- rma(y = surv, sei = std.err, method = "DL", data = test)

# t0.all = sort(unique(res_dat_surv$time))
# strata = levels(as.factor(res_dat_surv$strata))
# res.meta <- NULL

# for (istrata in strata) {
#   surv.meta <- NULL
#   for (t0 in t0.all) {
#     tmp <- res_dat_surv[res_dat_surv$time == t0 & res_dat_surv$strata == istrata, ]
#     tmp <- tmp %>% filter(outcome == "time_deceased_reg_elix")
#     if (nrow(tmp) != 0) {
#       if (nrow(tmp) == 1) {
#         junk.meta <- tmp$surv
#         junk.se <- tmp$std.err
#       } else {
#         junk <- rma(y = tmp$surv, sei = tmp$std.err, method = "DL") # metafor for each strata
#         junk.meta <- c(junk$beta)
#         junk.se <- c(junk$se)
#       }
#     }
#     surv.meta <- rbind(surv.meta, data.frame(surv = junk.meta, se = junk.se))
#   }
#   res.meta <- rbind(res.meta, data.frame(strata = istrata, time = t0.all, surv.meta))
# }

# # add the meta package derived weights from below 
# weights_pns <- combined_results %>% select(studlab, analysis, Weight.random)
# weights_cns <- combined_results %>% select(studlab, analysis, Weight.random)
# 
# weights_pns <- weights_pns %>% 
#   rename(site = "studlab", 
#          outcome = "analysis") %>% 
#   mutate(strata = "PNS")
# 
# weights_cns <- weights_cns %>% 
#   rename(site = "studlab", 
#          outcome = "analysis")
# 
# weights <- rbind(weights_pns, weights_cns)
# 
# res_dat_survx <- res_dat_surv %>%
#   left_join(., weights_cns, by = c("site", "outcome"))
# 
# ### alternatively, calcualte weight by square the standard error to obtain variance
# ### then take inverse of the variance
# res_dat_surv <- res_dat_surv %>% 
#   mutate(weight = 1/(std.err^2))

meta_surv_df <- res_dat_surv %>%
  ungroup() %>%  
  as.data.frame() %>% 
  filter(!total_event == 0) %>% 
  group_by(strata, outcome, time) %>%
  summarise(
    se = get_se(surv, std.err, site),
    meta_surv = get_surv(surv, std.err, site),
    .groups = "drop"
  ) %>%
  mutate(
    ymin = meta_surv - 1.96 * se,
    ymax = meta_surv + 1.96 * se,
    strata = str_replace(strata, "neuro_post=", ""),
    outcome = factor(outcome, levels = outcomes) %>%
      fct_recode(
        "Mortality" = "time_deceased_reg_elix",
        "Severity" = "time_severe_reg_elix",
        "Time to first discharge" = "time_first_discharge_reg_elix"
      )
  )

# refactor
meta_surv_df$strata <- as.factor(meta_surv_df$strata)
meta_surv_df$strata <- fct_recode(meta_surv_df$strata, "NNC" = "None")

meta_surv_df$strata <- factor(meta_surv_df$strata, levels=c("NNC", "CNS", "PNS"), labels=c("NNC", "CNS", "PNS"))

group.colors <- c(`NNC` = "darkgray", PNS = "slateblue", CNS ="tomato")


meta_surv_df %>%
  filter(time <= 60) %>% 
  ggplot(aes(
    x = time, y = meta_surv,
    color = strata,
  )) +
  geom_line(aes()) +
  # geom_ribbon(aes(ymin = ymin, ymax = ymax), alpha = 0.1, linetype = 2) +
  labs(color = NULL, y = NULL) +
  scale_colour_manual(values = group.colors) + 
  facet_wrap(~outcome, ncol = 3) +
# ggrepel::geom_text_repel(
#   data = . %>% filter(
#     time == last(time),
#     outcome == "Mortality"
#   ),
#   aes(
#     label = strata,
#     x = time + 10,
#     y = meta_surv,
#     color = strata
#   ), direction = "y"
# ) +
  coord_cartesian(clip = "off", ylim = c(0, 1), expand = FALSE) +
  xlab("Time (days)") + 
  ylab("Survival Probability") + 
  #guides(color = FALSE) +
  theme_classic() + 
  theme(legend.text=element_text(size=11)) + 
  guides(colour = guide_legend(override.aes = list(size=2)))
```

## Create Life-table

I need to copy the code for the res_dat_surv timepoint imputation in order to create the tables with outcomes and number of events, censored, and at risk

```{r eval=FALSE, include=FALSE}
time_dis_nwu <- NWU_results[["first_hosp_results"]][["cpns_results"]][["time_severe_reg_elix"]][["event_table_obfs"]] %>% 
  add_count(status, name = "n_timepoints") %>% 
  complete(time, nesting(status)) %>%
  arrange(time) %>% 
  group_by(status) %>%
  fill(n_timepoints, n.risk, n.event, n.censor, .direction = "downup") %>% 
  #filter(time %in% c(1, 30, 60)) %>% 
  ungroup()

time_dis_pitt <- UPITT_results[["first_hosp_results"]][["cpns_results"]][["time_severe_reg_elix"]][["event_table_obfs"]] %>% 
  add_count(status, name = "n_timepoints") %>% 
  complete(time, nesting(status)) %>%
  arrange(time) %>% 
  group_by(status) %>%
  fill(n_timepoints, n.risk, n.event, n.censor, .direction = "downup") %>% 
  filter(time %in% c(1, 30, 60)) %>% 
  ungroup()

time_dis_mgb <- MGB_results[["first_hosp_results"]][["cpns_results"]][["time_severe_reg_elix"]][["event_table_obfs"]] %>% 
  add_count(status, name = "n_timepoints") %>% 
  complete(time, nesting(status)) %>%
  arrange(time) %>% 
  group_by(status) %>%
  fill(n_timepoints, n.risk, n.event, n.censor, .direction = "downup") %>% 
  filter(time %in% c(1, 30, 60)) %>% 
  ungroup()


severe_results <- bind_rows(time_dis_nwu, time_dis_pitt, time_dis_mgb) %>% 
  group_by(time, status) %>% 
  mutate(n.risk_total = sum(n.risk),
         n.censor_total = sum(n.censor),
         n.event_total = sum(n.event)) %>% 
  distinct(time, n.risk_total, n.censor_total, n.event_total) %>% 
  pivot_wider()

severe_results1 <- severe_results %>% filter(time == 1)
severe_results30 <- severe_results %>% filter(time == 30)
severe_results60 <- severe_results %>% filter(time == 60)
```



### Alternatively, compute average survival by hand
Not evaluated for now.
Need to recompute `n_site`.

```{r eval=FALSE}
# res_dat %>%
#   group_by(strata, time, outcome) %>%
#   summarise(meta_surv = sum(surv * n_site) / sum(n_site), .groups = "drop") %>%
#   mutate(outcome = fct_rev(outcome)) %>%
#   ggplot(aes(
#     x = time, y = meta_surv,
#     color = fct_reorder2(strata, outcome, meta_surv)
#   )) +
#   geom_line(aes()) +
#   labs(color = NULL, y = NULL) +
#   rcartocolor::scale_color_carto_d() +
#   facet_wrap(~outcome) +
#   geom_text(
#     data = . %>% filter(
#       time == last(time),
#       outcome == "Mortality"
#     ),
#     aes(
#       label = strata,
#       x = time + 10,
#       y = meta_surv,
#       color = strata
#     ),
#     hjust = 0
#   ) +
#   coord_cartesian(clip = "off", ylim = c(0, 1), expand = FALSE) +
#   guides(color = FALSE) +
#   theme_classic() +
#   theme(plot.margin = margin(2, 50, 2, 2))
```

## Cox model

```{r}
cox_results <- list()
for (outcome_i in outcomes) {
  cox_results[[outcome_i]] <-
    site_results %>%
    lapply(get_cox_row, outcome = outcome_i) %>%
    bind_rows() %>%
    mutate(outcome = outcome_i)
}
test <- cox_results$time_deceased_reg_elix %>%
  filter(variable == "neuro_postCentral") %>%
  with(rma(yi = coef, sei = se.coef., random = ~ 1 | site, method = "DL"))
# cox_results$time_severe_reg_elix %>%
#   filter(variable == "neuro_postCentral") %>%
#   with(rma(yi = coef, sei = se.coef., method = "DL"))
# cox_results$time_first_discharge_reg_elix %>%
#   filter(variable == "neuro_postCentral") %>%
#   with(rma(yi = coef, sei = se.coef., method = "DL"))
# cox_results$time_last_discharge_reg_elix %>%
#   filter(variable == "neuro_postCentral") %>%
#   with(rma(yi = coef, sei = se.coef., method = "DL"))
```

## Random effects meta-analysis

```{r}
if (neuro_type_analyze == "binary_results") {
  variable_to_filter <- "neuro_postneuro_cond"
} else {
  variable_to_filter <- neuro_chr_to_analyze
}

run_meta_anlaysis <- function(variable) {
  
  for (outcome_i in outcomes) {
  meta_results[[outcome_i]] <-
    cox_results[[outcome_i]] %>%
    bind_rows() %>%
    data.frame() %>%
    filter(variable == variable_to_filter) %>%
    metagen(
      TE = coef,
      seTE = se.coef.,
      data = .,
      sm = "HR", # hazard ratios
      comb.random = TRUE,
      comb.fixed = FALSE,
      method.tau = "DL", # default tau method
      hakn = FALSE,
      prediction = TRUE,
      studlab = site
    )
}
  
}


```

**Abstract & format meta-results of interest**

```{r}
ma_combine <- list()
for (i in names(meta_results)) {
  TE <- meta_results[[i]][["TE"]]
  studlab <- meta_results[[i]][["studlab"]]
  upper <- meta_results[[i]][["upper"]]
  lower <- meta_results[[i]][["lower"]]
  TE.random <- meta_results[[i]][["TE.random"]]
  lower.random <- meta_results[[i]][["lower.random"]]
  upper.random <- meta_results[[i]][["upper.random"]]
  pval.random <- meta_results[[i]][["pval.random"]]
  Weight.random <- meta_results[[i]][["w.random"]]
  lower.predict <- meta_results[[i]][["lower.predict"]]
  upper.predict <- meta_results[[i]][["upper.predict"]]
  I2 <- meta_results[[i]][["I2"]]
  lower.I2 <- meta_results[[i]][["lower.I2"]]
  upper.I2 <- meta_results[[i]][["upper.I2"]]
  H <- meta_results[[i]][["H"]]
  lower.H <- meta_results[[i]][["H"]]
  upper.H <- meta_results[[i]][["upper.H"]]
  tau2 <- meta_results[[i]][["tau2"]]
  lower.tau2 <- meta_results[[i]][["lower.tau2"]]
  upper.tau2 <- meta_results[[i]][["upper.tau2"]]
  analysis <- paste(i)
  df <- cbind(
    analysis, studlab, TE, upper, lower, TE.random, lower.random, upper.random, Weight.random,
    pval.random, lower.predict, upper.predict, I2, lower.I2, upper.I2, H, lower.H, upper.H,
    tau2, lower.tau2, upper.tau2
  )

  ma_combine[[i]] <- df
}

combined_results <- do.call(rbind.data.frame, ma_combine)
```

NUH has missing value for `time_to_last_disharge` - we will exclude

```{r eval=FALSE, include=FALSE}
if(neuro_chr_to_analyze == "neuro_postPeripheral") { 
  
  combined_results <- combined_results %>% 
    filter(!is.na(TE))
  }
```


We will convert our log(HR) to HR to facilitate interpretation and we will also perform appropriate rounding and rename variables here

```{r}
combined_results <- combined_results %>%
  group_by(analysis, studlab) %>%
  arrange(analysis, studlab) %>%
  ungroup() %>%
  mutate_at(vars(TE:upper.tau2), ~ as.character(.) %>% as.numeric()) %>%
  mutate_at(vars(TE:upper.predict, -pval.random, -Weight.random), ~ if_else(analysis == "time_deceased_reg_elix", exp(.),
    if_else(analysis == "time_severe_reg_elix", exp(.),
      if_else(analysis == "time_last_discharge_reg_elix", exp(.),
        if_else(analysis == "time_first_discharge_reg_elix", exp(.), .)
      )
    )
  )) %>%
  mutate_at(vars(TE:upper.tau2, -pval.random), ~ round(., 2)) %>%
  mutate(CI.random = paste("(", lower.random, ",", upper.random, ")")) %>%
  rename(
    "Site" = studlab,
    "Estimate" = TE,
    "p-value" = pval.random,
    "CI.High" = upper,
    "CI.Low" = lower,
    "CI" = CI.random
  )
```

Add blank rows to facilitate formatting

```{r}
df_new <- as.data.frame(lapply(combined_results, as.character), stringsAsFactors = FALSE)

sorted_sites <- sorted_sites[!sorted_sites %in% c("NUH_results")]
n_sites = length(sorted_sites)

# add blank rows to facilitate formatting
combined_results <- combined_results %>%
  add_row(.before = 1) %>%
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+1) %>%
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+n_sites+2) %>%
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+(n_sites+n_sites+3)) %>% 
  add_row(.after = nrow(.))

# move analysis label up
combined_results <- combined_results %>% 
  fill(analysis, .direction = "up") %>%
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+1) %>% 
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+n_sites+3) %>% 
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+n_sites+n_sites+5)
```

Add row names to facilitate future subset by analysis

```{r}
combined_results <- combined_results %>% data.frame()

# create temp analysis column
combined_results <- combined_results %>% 
  mutate(analysis_temp = analysis) %>% 
  fill(analysis_temp, .direction = "down")

combined_results$row_num <- seq_len(nrow(combined_results))
combined_results <- combined_results %>% mutate(new_row = paste0(analysis_temp, "_", row_num))

row.names(combined_results) <- combined_results$new_row
combined_results <- combined_results %>% select(-row_num, -new_row, -analysis_temp)
```

Carry over name of the analysis to the blank row

```{r}
# # Add the analysis labels to the original site level rows - these will be our labels for the forest plots
# combined_resultsx <- combined_results %>%
#   fill(analysis, .direction = "up") %>%
#   mutate(
#     id = seq_len(nrow(.)),
#     Site = if_else(is.na(Site), analysis, Site),
#     lag_Site = lag(Site),
#     lag_Site = if_else(is.na(lag_Site), "First", lag_Site),
#     Site = ifelse(Site == lag_Site, paste(Site, "_", id), Site)
#   ) %>%
#   select(-analysis, -lag_Site, -id) %>%
#   rename("Analysis" = Site)
```

Indent site results and create a new Analysis column to be our forest plot labels

```{r}
# convert columns back to numeric
combined_results <- combined_results %>%
  mutate_at(vars(Estimate:upper.tau2), ~ as.character(.) %>% as.numeric())

combined_results$Analysis <- ifelse(is.na(combined_results$Estimate),
  combined_results$analysis,
  paste0("   ", combined_results$Site)
)
```

make the new Analysis label blank if not representing the site

```{r}
combined_results <- combined_results %>% data.frame()

combined_results <- combined_results %>%
  mutate(Analysis = ifelse(grepl("_", Analysis), NA, Analysis))
```

Additional formatting to integrate the random-effects meta analysis results with the regression estimates

```{r}
# select the variables representing results from the overall meta-analysis
overall_results <- c(
  "TE.random", "upper.random", "lower.random", "p.value", "CI",
  "lower.predict", "upper.predict", "I2", "lower.I2", "upper.I2", "H",
  "lower.H", "upper.H", "tau2", "lower.tau2", "upper.tau2"
)
# fill these columns up to the first overall meta-analysis results row where there are currently NAs
combined_results <- combined_results %>%
  fill(overall_results, .direction = "down")

# subsequently, make the site level information NA for the following columns
combined_results <- combined_results %>%
  mutate_at(vars(overall_results), ~ ifelse(is.na(Estimate), .x, NA))

# make sure the empty row at the start of each analysis is empty
combined_results <- combined_results %>% 
  mutate_at(vars(overall_results), ~ ifelse(!is.na(analysis) & is.na(Site), NA, .x ))

# move meta analysis results to the same columns as the site regression estimates
combined_results$Estimate <- ifelse(is.na(combined_results$Estimate), combined_results$TE.random, combined_results$Estimate)
combined_results$CI.High <- ifelse(is.na(combined_results$CI.High), combined_results$upper.random, combined_results$CI.High)
combined_results$CI.Low <- ifelse(is.na(combined_results$CI.Low), combined_results$lower.random, combined_results$CI.Low)

# create new 'Estimate' column that we can append CIs
# format the p-values so we don't lose trailing zeros which occurs with as.character()
# the below steps seem long but best way as of now to ensure that we can add < signs and asterisks when dealing with numeric and character data
combined_results <- combined_results %>%
  mutate(
    "Estimate " = paste(Estimate, "(", CI.Low, ",", CI.High, ")"),
    p.value_format = ifelse(p.value > 0.01, round(p.value, 2), round(p.value, 3)),
    "P-value" = ifelse(p.value < 0.001, "< .001*", as.character(p.value_format)),
    "P-value" = ifelse(p.value >= 0.001 & p.value < 0.05, paste(`P-value`, "*"), `P-value`)
  ) %>%
  select(-p.value_format)

combined_results$p.value[combined_results$p.value == "NA"] <- ""
combined_results[is.na(combined_results)] <- ""
# make the second analysis row blank
cols <- colnames(combined_results)
combined_results[, cols] <- as.data.frame(lapply(cols,
  FUN = function(x) ifelse(combined_results$Analysis == "" & dplyr::lead(combined_results$Analysis, default = first(combined_results$Analysis)) != "", "", combined_results[, x])
))
# convert back to numeric
combined_results <- combined_results %>%
  mutate_at(vars(overall_results, Estimate, Weight.random, CI.High, CI.Low), ~ as.character(.) %>% as.numeric()) %>%
  mutate(
    Analysis = as.character(Analysis),
    Analysis = ifelse(is.na(Estimate), "Site", Analysis)
  ) %>%
  select(-TE.random, -lower.random, -upper.random)
```

### Create Results Table

```{r}
results_table <- combined_results %>%
  select(
    Analysis, `Estimate `, Weight.random, p.value, `P-value`,
    lower.predict, upper.predict,
    I2, lower.I2, upper.I2,
    H, lower.H, upper.H,
    tau2, lower.tau2, upper.tau2
  ) %>%
  mutate(
    Predict.CI = paste("(", lower.predict, ",", upper.predict, ")"),
    I2.CI = paste("(", lower.I2, ",", upper.I2, ")"),
    H.CI = paste("(", lower.H, ",", upper.H, ")"),
    tau2.CI = paste("(", lower.tau2, ",", upper.tau2, ")")
  ) %>%
  select(-lower.predict, -upper.predict, -lower.I2, -upper.I2, -lower.H, -upper.H, -lower.tau2, -upper.tau2) %>%
  select(Analysis, `Estimate `, Weight.random, p.value, `P-value`, Predict.CI, I2, I2.CI, tau2, tau2.CI)
results_table[results_table == "( NA , NA )"] <- ""
results_table[is.na(results_table)] <- ""
write.csv(results_table, file = paste0("meta_tables/surivival_analysis_", neuro_type_analyze, neuro_chr_to_analyze, ".csv"))
```

Add 'overall effect' labels for forest plots

```{r}
combined_results <- combined_results %>% 
  mutate(Analysis = if_else(Analysis == "" & !is.na(Estimate), "Overall Estimate", Site)) %>% 
  ungroup()

# remove the duplicate rows at the end
combined_results <- combined_results %>%
  head(., -2)
```

## Results

Define a vector of invalid sites. As of now, ICSM and NUH, have such low counts that CIs and estimates are very high/low. To standardize the plots, we will want to abstract the min/max values while excluding any outlier sites like ICSM and NUH

```{r}
invalid_sites <- sorted_sites[sorted_sites %in% c("ICSM_results", "GOSH_results")]
invalid_sites <- gsub("_results", "", invalid_sites)
# indent the sites to facilitate mapping with our combined_results df
```

create a scale function to identify the min and max CI for each site, excluding sites with values of 'Inf' or our invalid sites

```{r}
scale_plot <- function(combined_results_df) {
  scale <- combined_results_df %>%
    filter(
      !Analysis %in% invalid_sites,
      !CI.Low == "Inf",
      !CI.High == "Inf"
    ) %>%
    mutate(
      min_est = min(CI.Low, na.rm = TRUE) - 1,
      max_est = max(CI.High, na.rm = TRUE) + 1,
      min_est = if_else(min_est + 1 >= -1, min(CI.Low, na.rm = TRUE)-0.1, min_est),
      min_est = if_else(min_est > 1, 0.5, min_est),
      max_est = if_else(max_est - 1 < 1, 1.1, max_est)) %>%
    distinct(min_est, max_est)

  return(scale)
}
```


### **Time to First Discharge**

```{r fig.width=8, message=FALSE, warning=FALSE}
length_stay_first_results <- combined_results %>%
  slice(grep(paste("time_first_discharge_reg_elix", collapse = "|"), row.names(.)))
## define forest plot shapes
# shape #16 is normal circle; #18 is diamond
shapes <- rep(16, times = nrow(length_stay_first_results))
shapes[length(shapes)] <- 18
sizes <- rep(3.25, times = nrow(length_stay_first_results))
sizes[length(sizes)] <- 5
scale <- scale_plot(length_stay_first_results)

forester(
  left_side_data = length_stay_first_results %>% select(Analysis),
  estimate = length_stay_first_results$Estimate,
  ci_low = length_stay_first_results$CI.Low,
  ci_high = length_stay_first_results$CI.High,
  right_side_data = length_stay_first_results[, c("Estimate ", "P-value")],
  display = TRUE,
  font_family = "arial",
  arrows = TRUE,
  arrow_labels = c("Decreased Risk", "Increased Risk"),
  null_line_at = 1,
  xlim = c(scale$min_est, scale$max_est),
  xbreaks = c(scale$min_est, 1, scale$max_est),
  point_sizes = sizes,
  point_shapes = shapes,
  file_path = here::here(paste0("figs/surivial_time_first_discharge", "_", neuro_type_analyze, "_", neuro_chr_to_analyze, ".png")))
```

### **Time to Severe COVID-19**

```{r fig.width=8, message=FALSE, warning=FALSE}
time_severe_results <- combined_results %>%
  slice(grep(paste("time_severe_reg_elix", collapse = "|"), row.names(.))) %>% 
  distinct()
## define forest plot shapes
# shape #16 is normal circle; #18 is diamond
shapes <- rep(16, times = nrow(time_severe_results))
shapes[length(shapes)] <- 18
sizes <- rep(3.25, times = nrow(time_severe_results))
sizes[length(sizes)] <- 5
scale <- scale_plot(time_severe_results)
forester(
  left_side_data = time_severe_results %>% select(Analysis),
  estimate = time_severe_results$Estimate,
  ci_low = time_severe_results$CI.Low,
  ci_high = time_severe_results$CI.High,
  right_side_data = time_severe_results[, c("Estimate ", "P-value")],
  display = TRUE,
  font_family = "arial",
  arrows = TRUE,
  arrow_labels = c("Decreased Risk", "Increased Risk"),
  null_line_at = 1,
  xlim = c(scale$min_est, scale$max_est),
  xbreaks = c(scale$min_est, 1, scale$max_est),
  point_sizes = sizes,
  point_shapes = shapes,
  file_path = here::here(paste0("figs/surivial_time_to_severe", "_", neuro_type_analyze, "_", neuro_chr_to_analyze, ".png")))
```


### **Time to Mortality**

```{r fig.width=8, message=FALSE, warning=FALSE}
time_death_results <- combined_results %>%
  slice(grep(paste("time_deceased_reg_elix", collapse = "|"), row.names(.)))
## define forest plot shapes
# shape #16 is normal circle; #18 is diamond
shapes <- rep(16, times = nrow(time_death_results))
shapes[length(shapes)] <- 18
sizes <- rep(3.25, times = nrow(time_death_results))
sizes[length(sizes)] <- 5
scale <- scale_plot(time_death_results)
forester(
  left_side_data = time_death_results %>% select(Analysis),
  estimate = time_death_results$Estimate,
  ci_low = time_death_results$CI.Low,
  ci_high = time_death_results$CI.High,
  right_side_data = time_death_results[, c("Estimate ", "P-value")],
  display = TRUE,
  font_family = "arial",
  arrows = TRUE,
  arrow_labels = c("Decreased Risk", "Increased Risk"),
  null_line_at = 1,
  xlim = c(scale$min_est, scale$max_est),
  xbreaks = c(scale$min_est, 1, scale$max_est),
  point_sizes = sizes,
  point_shapes = shapes,
  file_path = here::here(paste0("figs/surivial_time_to_death", "_", neuro_type_analyze, "_", neuro_chr_to_analyze, ".png")))
```
