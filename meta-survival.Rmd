---
title: "Meta-Analysis"
output: html_document
---

Perform primary meta-analysis on Cox-PH models from each site.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(metafor)
library(meta)
source("R/forester_custom.R")
```

```{r}
rdas <- list.files(
  path = "results",
  pattern = ".rda",
  full.names = TRUE
)
for (rda in rdas) {
  load(rda)
}
rm(rdas, rda)

# create a list of all rda files with "result" suffix
# check for sites we may want to exclude
googlesheets4::gs4_deauth()
site_google_url <- "https://docs.google.com/spreadsheets/d/1epcYNd_0jCUMktOHf8mz5v651zy1JALD6PgzobrGWDY/edit?usp=sharing"
site_params <- googlesheets4::read_sheet(site_google_url, sheet = 1)
site_avails <- googlesheets4::read_sheet(site_google_url, sheet = 2)

sorted_sites <- site_avails %>%
  filter(date_v3_received == 1) %>%
  pull(siteid) %>%
  paste("results", sep = "_")
```


```{r}
site_results <- mget(ls(pattern = "results"))
```


```{r echo=TRUE}
sorted_sites <- sorted_sites[!(sorted_sites %in% c("NUH_results", "BCH_results", "GOSH_results"))]
site_results[['NUH_results']] <- NULL
site_results[['BCH_results']] <- NULL
site_results[['GOSH_results']] <- NULL
```

*I received a lot of missing values and a warning: 'Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.' - when trying to run a meta-analysis on just the pediatric hospitals*

```{r}
# sorted_sites <- sorted_sites[(sorted_sites %in% c("BCH_results", "GOSH_results"))]
# site_results <- site_results[c("BCH_results", "GOSH_results")]
```

change ```neuro_chr_to_analyze``` in order to change analysis to 'neuro_postCentral', 'neuro_postPeripheral', 'neuro_postBoth'
change ```neuro_type_analyze``` in order to change analysis to 'cpns_results' or 'binary_results'

```{r}
neuro_chr_to_analyze <- "neuro_postCentral"
#neuro_chr_to_analyze <- "neuro_postPeripheral"
neuro_type_analyze <- "cpns_results"

site_results <- mget(ls(pattern = "result"))
site_results <- site_results[sorted_sites]
```

## Define outcomes

```{r}
outcomes <-
  c(
    "time_first_discharge_reg_elix",
    "time_severe_reg_elix",
    "time_deceased_reg_elix"
  )
```


## Cox model

```{r}
get_cox_row <- function(df,
                        outcome = "time_severe_reg_elix",
                        period = "first_hosp_results",
                        neuro_type = neuro_type_analyze) {
  cox_output <- df[[c(period, neuro_type, outcome, "cox")]]
  coefficients(cox_output) %>%
    data.frame() %>%
    mutate(
      site = df$site
      #n_site = cox_output$n
    ) %>%
    rownames_to_column("variable")
}

cox_results <- list()

for (outcome_i in outcomes) {
  cox_results[[outcome_i]] <-
    site_results %>%
    lapply(get_cox_row, outcome = outcome_i) %>%
    bind_rows() %>%
    mutate(outcome = outcome_i)
}

cox_results$time_severe_reg_elix %>%
  filter(variable == "neuro_postCentral") %>%
  with(rma(yi = coef, sei = se.coef., method = "DL"))
# cox_results$time_first_discharge_reg_elix %>%
#   filter(variable == "neuro_postCentral") %>%
#   with(rma(yi = coef, sei = se.coef., method = "DL"))
# cox_results$time_last_discharge_reg_elix %>%
#   filter(variable == "neuro_postCentral") %>%
#   with(rma(yi = coef, sei = se.coef., method = "DL"))
```

## Random effects meta-analysis

```{r}
meta_results <- list()

for (outcome_i in outcomes) {
  meta_results[[outcome_i]] <-
    cox_results[[outcome_i]] %>%
    bind_rows() %>%
    data.frame() %>%
    filter(variable == neuro_chr_to_analyze) %>%
    metagen(
      TE = coef,
      seTE = se.coef.,
      data = .,
      sm = "HR", # hazard ratios
      comb.random = TRUE,
      comb.fixed = FALSE,
      method.tau = "DL", # default tau method
      hakn = FALSE,
      prediction = TRUE,
      studlab = site
    )
}



```

**Abstract & format meta-results of interest**

```{r}
ma_combine <- list()
for (i in names(meta_results)) {
  TE <- meta_results[[i]][["TE"]]
  studlab <- meta_results[[i]][["studlab"]]
  upper <- meta_results[[i]][["upper"]]
  lower <- meta_results[[i]][["lower"]]
  TE.random <- meta_results[[i]][["TE.random"]]
  lower.random <- meta_results[[i]][["lower.random"]]
  upper.random <- meta_results[[i]][["upper.random"]]
  pval.random <- meta_results[[i]][["pval.random"]]
  Weight.random <- meta_results[[i]][["w.random"]]
  lower.predict <- meta_results[[i]][["lower.predict"]]
  upper.predict <- meta_results[[i]][["upper.predict"]]
  I2 <- meta_results[[i]][["I2"]]
  lower.I2 <- meta_results[[i]][["lower.I2"]]
  upper.I2 <- meta_results[[i]][["upper.I2"]]
  H <- meta_results[[i]][["H"]]
  lower.H <- meta_results[[i]][["H"]]
  upper.H <- meta_results[[i]][["upper.H"]]
  tau2 <- meta_results[[i]][["tau2"]]
  lower.tau2 <- meta_results[[i]][["lower.tau2"]]
  upper.tau2 <- meta_results[[i]][["upper.tau2"]]
  analysis <- paste(i)
  df <- cbind(
    analysis, studlab, TE, upper, lower, TE.random, lower.random, upper.random, Weight.random,
    pval.random, lower.predict, upper.predict, I2, lower.I2, upper.I2, H, lower.H, upper.H,
    tau2, lower.tau2, upper.tau2
  )

  ma_combine[[i]] <- df
}

combined_results <- do.call(rbind.data.frame, ma_combine)
```

### save weights to generate the survival curves

```{r}
if (neuro_chr_to_analyze == "neuro_postCentral") {
  
  cns_weights <- combined_results %>% 
  select(analysis, studlab, Weight.random) %>% 
  mutate(strata = "CNS")

  # Save weights
  save(cns_weights, file = "survival_model/cns_weights.rda")
  
} else {
  
  pns_weights <- combined_results %>% 
  select(analysis, studlab, Weight.random) %>% 
  mutate(strata = "PNS")

  # Save weights
  save(pns_weights, file = "survival_model/pns_weights.rda")
  
}
```


We will convert our log(HR) to HR to facilitate interpretation and we will also perform appropriate rounding and rename variables here

```{r}
combined_results <- combined_results %>%
  group_by(analysis, studlab) %>%
  arrange(analysis, studlab) %>%
  ungroup() %>%
  mutate_at(vars(TE:upper.tau2), ~ as.character(.) %>% as.numeric()) %>%
  mutate_at(vars(TE:upper.predict, -pval.random, -Weight.random), ~ if_else(analysis == "time_deceased_reg_elix", exp(.),
    if_else(analysis == "time_severe_reg_elix", exp(.),
      if_else(analysis == "time_last_discharge_reg_elix", exp(.),
        if_else(analysis == "time_first_discharge_reg_elix", exp(.), .)
      )
    )
  )) %>%
  mutate_at(vars(TE:upper.tau2, -pval.random), ~ round(., 2)) %>%
  mutate(CI.random = paste("(", lower.random, ",", upper.random, ")")) %>%
  rename(
    "Site" = studlab,
    "Estimate" = TE,
    "p-value" = pval.random,
    "CI.High" = upper,
    "CI.Low" = lower,
    "CI" = CI.random
  )
```

Add blank rows to facilitate formatting

```{r}
df_new <- as.data.frame(lapply(combined_results, as.character), stringsAsFactors = FALSE)

sorted_sites <- sorted_sites[!sorted_sites %in% c("NUH_results")]
n_sites = length(sorted_sites)

# add blank rows to facilitate formatting
combined_results <- combined_results %>%
  add_row(.before = 1) %>%
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+1) %>%
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+n_sites+2) %>%
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+(n_sites+n_sites+3)) %>% 
  add_row(.after = nrow(.))

# move analysis label up
combined_results <- combined_results %>% 
  fill(analysis, .direction = "up") %>%
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+1) %>% 
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+n_sites+3) %>% 
  add_row(.after = nrow(df_new %>% filter(analysis == "time_deceased_reg_elix"))+n_sites+n_sites+5)
```

Add row names to facilitate future subset by analysis

```{r}
combined_results <- combined_results %>% data.frame()

# create temp analysis column
combined_results <- combined_results %>% 
  mutate(analysis_temp = analysis) %>% 
  fill(analysis_temp, .direction = "down")

combined_results$row_num <- seq_len(nrow(combined_results))
combined_results <- combined_results %>% mutate(new_row = paste0(analysis_temp, "_", row_num))

row.names(combined_results) <- combined_results$new_row
combined_results <- combined_results %>% select(-row_num, -new_row, -analysis_temp)
```

Indent site results and create a new Analysis column to be our forest plot labels

```{r}
# convert columns back to numeric
combined_results <- combined_results %>%
  mutate_at(vars(Estimate:upper.tau2), ~ as.character(.) %>% as.numeric())

combined_results$Analysis <- ifelse(is.na(combined_results$Estimate),
  combined_results$analysis,
  paste0("   ", combined_results$Site)
)
```

make the new Analysis label blank if not representing the site

```{r}
combined_results <- combined_results %>% data.frame()

combined_results <- combined_results %>%
  mutate(Analysis = ifelse(grepl("_", Analysis), NA, Analysis))
```

Additional formatting to integrate the random-effects meta analysis results with the regression estimates

```{r}
# select the variables representing results from the overall meta-analysis
overall_results <- c(
  "TE.random", "upper.random", "lower.random", "p.value", "CI",
  "lower.predict", "upper.predict", "I2", "lower.I2", "upper.I2", "H",
  "lower.H", "upper.H", "tau2", "lower.tau2", "upper.tau2"
)
# fill these columns up to the first overall meta-analysis results row where there are currently NAs
combined_results <- combined_results %>%
  fill(overall_results, .direction = "down")

# subsequently, make the site level information NA for the following columns
combined_results <- combined_results %>%
  mutate_at(vars(overall_results), ~ ifelse(is.na(Estimate), .x, NA))

# make sure the empty row at the start of each analysis is empty
combined_results <- combined_results %>% 
  mutate_at(vars(overall_results), ~ ifelse(!is.na(analysis) & is.na(Site), NA, .x ))

# move meta analysis results to the same columns as the site regression estimates
combined_results$Estimate <- ifelse(is.na(combined_results$Estimate), combined_results$TE.random, combined_results$Estimate)
combined_results$CI.High <- ifelse(is.na(combined_results$CI.High), combined_results$upper.random, combined_results$CI.High)
combined_results$CI.Low <- ifelse(is.na(combined_results$CI.Low), combined_results$lower.random, combined_results$CI.Low)

# create new 'Estimate' column that we can append CIs
# format the p-values so we don't lose trailing zeros which occurs with as.character()
# the below steps seem long but best way as of now to ensure that we can add < signs and asterisks when dealing with numeric and character data
combined_results <- combined_results %>%
  mutate(
    "Estimate " = paste(Estimate, "(", CI.Low, ",", CI.High, ")"),
    p.value_format = ifelse(p.value > 0.01, round(p.value, 2), round(p.value, 3)),
    "P-value" = ifelse(p.value < 0.001, "< .001*", as.character(p.value_format)),
    "P-value" = ifelse(p.value >= 0.001 & p.value < 0.05, paste(`P-value`, "*"), `P-value`)
  ) %>%
  select(-p.value_format)

combined_results$p.value[combined_results$p.value == "NA"] <- ""
combined_results[is.na(combined_results)] <- ""
# make the second analysis row blank
cols <- colnames(combined_results)
combined_results[, cols] <- as.data.frame(lapply(cols,
  FUN = function(x) ifelse(combined_results$Analysis == "" & dplyr::lead(combined_results$Analysis, default = first(combined_results$Analysis)) != "", "", combined_results[, x])
))
# convert back to numeric
combined_results <- combined_results %>%
  mutate_at(vars(overall_results, Estimate, Weight.random, CI.High, CI.Low), ~ as.character(.) %>% as.numeric()) %>%
  mutate(
    Analysis = as.character(Analysis),
    Analysis = ifelse(is.na(Estimate), "Site", Analysis)
  ) %>%
  select(-TE.random, -lower.random, -upper.random)
```

### Create Results Table

```{r}
results_table <- combined_results %>%
  select(
    Analysis, `Estimate `, Weight.random, p.value, `P-value`,
    lower.predict, upper.predict,
    I2, lower.I2, upper.I2,
    H, lower.H, upper.H,
    tau2, lower.tau2, upper.tau2
  ) %>%
  mutate(
    Predict.CI = paste("(", lower.predict, ",", upper.predict, ")"),
    I2.CI = paste("(", lower.I2, ",", upper.I2, ")"),
    H.CI = paste("(", lower.H, ",", upper.H, ")"),
    tau2.CI = paste("(", lower.tau2, ",", upper.tau2, ")")
  ) %>%
  select(-lower.predict, -upper.predict, -lower.I2, -upper.I2, -lower.H, -upper.H, -lower.tau2, -upper.tau2) %>%
  select(Analysis, `Estimate `, Weight.random, p.value, `P-value`, Predict.CI, I2, I2.CI, tau2, tau2.CI)
results_table[results_table == "( NA , NA )"] <- ""
results_table[is.na(results_table)] <- ""
write.csv(results_table, file = paste0("meta_tables/surivival_analysis_", neuro_type_analyze, neuro_chr_to_analyze, ".csv"))
```

Add 'overall effect' labels for forest plots

```{r}
combined_results <- combined_results %>% 
  mutate(Analysis = if_else(Analysis == "" & !is.na(Estimate), "Overall Estimate", Site)) %>% 
  ungroup()

# remove the duplicate rows at the end
combined_results <- combined_results %>%
  head(., -2)
```

## Results

Define a vector of invalid sites for those sites that have such low counts that CIs and estimates are very high/low. To standardize the plots, we will want to abstract the min/max values while excluding any outlier (ie: Invalid) sites

```{r}
if (neuro_chr_to_analyze == "neuro_postCentral") {

  invalid_sites <- sorted_sites[sorted_sites %in% c("ICSM_results", "BCH_results")]
  invalid_sites <- gsub("_results", "", invalid_sites)

} else {
  
  invalid_sites <- sorted_sites[sorted_sites %in% c("ICSM_results", "GOSH_results")]
  invalid_sites <- gsub("_results", "", invalid_sites)
}
```

create a scale function to identify the min and max CI for each site, excluding sites with values of 'Inf' or our invalid sites

```{r}
scale_plot <- function(combined_results_df) {
  scale <- combined_results_df %>%
    filter(
      !Analysis %in% invalid_sites,
      !CI.Low == "Inf",
      !CI.High == "Inf"
    ) %>%
    mutate(
      min_est = min(CI.Low, na.rm = TRUE) - 1,
      max_est = max(CI.High, na.rm = TRUE) + 1,
      min_est = if_else(min_est + 1 >= -1, min(CI.Low, na.rm = TRUE)-0.1, min_est),
      min_est = if_else(min_est > 1, 0.5, min_est),
      max_est = if_else(max_est - 1 < 1, 1.1, max_est)) %>%
    distinct(min_est, max_est)

  return(scale)
}
```


### **Time to First Discharge**

```{r fig.width=8, message=FALSE, warning=FALSE}
length_stay_first_results <- combined_results %>%
  slice(grep(paste("time_first_discharge_reg_elix", collapse = "|"), row.names(.)))
## define forest plot shapes
# shape #16 is normal circle; #18 is diamond
shapes <- rep(16, times = nrow(length_stay_first_results))
shapes[length(shapes)] <- 18
sizes <- rep(3.25, times = nrow(length_stay_first_results))
sizes[length(sizes)] <- 5
scale <- scale_plot(length_stay_first_results)

forester(
  left_side_data = length_stay_first_results %>% select(Analysis),
  estimate = length_stay_first_results$Estimate,
  ci_low = length_stay_first_results$CI.Low,
  ci_high = length_stay_first_results$CI.High,
  right_side_data = length_stay_first_results[, c("Estimate ", "P-value")],
  display = TRUE,
  font_family = "arial",
  arrows = TRUE,
  arrow_labels = c("Decreased Risk", "Increased Risk"),
  null_line_at = 1,
  xlim = c(scale$min_est, scale$max_est),
  xbreaks = c(scale$min_est, 1, scale$max_est),
  point_sizes = sizes,
  point_shapes = shapes,
  file_path = here::here(paste0("figs/surivial_time_first_discharge", "_", neuro_type_analyze, "_", neuro_chr_to_analyze, ".png")))
```

### **Time to Severe COVID-19**

```{r fig.width=8, message=FALSE, warning=FALSE}
time_severe_results <- combined_results %>%
  slice(grep(paste("time_severe_reg_elix", collapse = "|"), row.names(.))) %>% 
  distinct()
## define forest plot shapes
# shape #16 is normal circle; #18 is diamond
shapes <- rep(16, times = nrow(time_severe_results))
shapes[length(shapes)] <- 18
sizes <- rep(3.25, times = nrow(time_severe_results))
sizes[length(sizes)] <- 5
scale <- scale_plot(time_severe_results)
forester(
  left_side_data = time_severe_results %>% select(Analysis),
  estimate = time_severe_results$Estimate,
  ci_low = time_severe_results$CI.Low,
  ci_high = time_severe_results$CI.High,
  right_side_data = time_severe_results[, c("Estimate ", "P-value")],
  display = TRUE,
  font_family = "arial",
  arrows = TRUE,
  arrow_labels = c("Decreased Risk", "Increased Risk"),
  null_line_at = 1,
  xlim = c(scale$min_est, scale$max_est),
  xbreaks = c(scale$min_est, 1, scale$max_est),
  point_sizes = sizes,
  point_shapes = shapes,
  file_path = here::here(paste0("figs/surivial_time_to_severe", "_", neuro_type_analyze, "_", neuro_chr_to_analyze, ".png")))
```


### **Time to Mortality**

```{r fig.width=8, message=FALSE, warning=FALSE}
time_death_results <- combined_results %>%
  slice(grep(paste("time_deceased_reg_elix", collapse = "|"), row.names(.)))
## define forest plot shapes
# shape #16 is normal circle; #18 is diamond
shapes <- rep(16, times = nrow(time_death_results))
shapes[length(shapes)] <- 18
sizes <- rep(3.25, times = nrow(time_death_results))
sizes[length(sizes)] <- 5
scale <- scale_plot(time_death_results)
forester(
  left_side_data = time_death_results %>% select(Analysis),
  estimate = time_death_results$Estimate,
  ci_low = time_death_results$CI.Low,
  ci_high = time_death_results$CI.High,
  right_side_data = time_death_results[, c("Estimate ", "P-value")],
  display = TRUE,
  font_family = "arial",
  arrows = TRUE,
  arrow_labels = c("Decreased Risk", "Increased Risk"),
  null_line_at = 1,
  xlim = c(scale$min_est, scale$max_est),
  xbreaks = c(scale$min_est, 1, scale$max_est),
  point_sizes = sizes,
  point_shapes = shapes,
  file_path = here::here(paste0("figs/surivial_time_to_death", "_", neuro_type_analyze, "_", neuro_chr_to_analyze, ".png")))
```







